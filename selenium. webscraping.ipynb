{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import pandas as pd\n",
    "import selenium \n",
    "from selenium import webdriver\n",
    "import time\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#1 \n",
    "Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10 jobs data.\n",
    "This task will be done in following steps:\n",
    "1. first get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Analyst” in “Skill,Designations,Companies” field and enter “Bangalore” in “enter the location” field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Experiance_Required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist / Data Analyst -Business Analyst</td>\n",
       "      <td>Mumbai, Hyderabad/Secunderabad, Pune, Gurgaon/...</td>\n",
       "      <td>Inflexion Analytix Private Limited</td>\n",
       "      <td>0-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hiring Data Analysts For E commerce Platform |...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Allegis Services India Pvt. Ltd.\\n3.8\\n(205 Re...</td>\n",
       "      <td>0-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Assistant Vice President - MIS &amp; Reporting ( B...</td>\n",
       "      <td>Mumbai, Bangalore/Bengaluru</td>\n",
       "      <td>INTERTRUSTVITEOS CORPORATE AND FUND SERVICES P...</td>\n",
       "      <td>12-18 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Applied Materials\\n4.1\\n(94 Reviews)</td>\n",
       "      <td>7-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hiring For Data Analyst/ MIS Reporting Analyst...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>PHARMACEUTICAL RESEARCH ASSOCIATES INDIA Pvt L...</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DA - Urgent Opening For Data Analyst BFSI Doma...</td>\n",
       "      <td>Kolkata, Hyderabad/Secunderabad, Pune, Ahmedab...</td>\n",
       "      <td>Tata Consultancy Services Ltd.\\n4.0\\n(21095 Re...</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Analyst - Informatica MDM</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Shell India Markets Private Limited\\n4.1\\n(623...</td>\n",
       "      <td>6-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Myntra Designs Pvt. Ltd.\\n4.2\\n(742 Reviews)</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Myntra Designs Pvt. Ltd.\\n4.2\\n(742 Reviews)</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Myntra Designs Pvt. Ltd.\\n4.2\\n(742 Reviews)</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job_Title  \\\n",
       "0    Data Scientist / Data Analyst -Business Analyst   \n",
       "1  Hiring Data Analysts For E commerce Platform |...   \n",
       "2  Assistant Vice President - MIS & Reporting ( B...   \n",
       "3                                       Data Analyst   \n",
       "4  Hiring For Data Analyst/ MIS Reporting Analyst...   \n",
       "5  DA - Urgent Opening For Data Analyst BFSI Doma...   \n",
       "6                     Data Analyst - Informatica MDM   \n",
       "7                                       Data Analyst   \n",
       "8                                       Data Analyst   \n",
       "9                                       Data Analyst   \n",
       "\n",
       "                                            Location  \\\n",
       "0  Mumbai, Hyderabad/Secunderabad, Pune, Gurgaon/...   \n",
       "1                                Bangalore/Bengaluru   \n",
       "2                        Mumbai, Bangalore/Bengaluru   \n",
       "3                                Bangalore/Bengaluru   \n",
       "4                                Bangalore/Bengaluru   \n",
       "5  Kolkata, Hyderabad/Secunderabad, Pune, Ahmedab...   \n",
       "6                                Bangalore/Bengaluru   \n",
       "7                                Bangalore/Bengaluru   \n",
       "8                                Bangalore/Bengaluru   \n",
       "9                                Bangalore/Bengaluru   \n",
       "\n",
       "                                        Company_Name Experiance_Required  \n",
       "0                 Inflexion Analytix Private Limited             0-3 Yrs  \n",
       "1  Allegis Services India Pvt. Ltd.\\n3.8\\n(205 Re...             0-5 Yrs  \n",
       "2  INTERTRUSTVITEOS CORPORATE AND FUND SERVICES P...           12-18 Yrs  \n",
       "3               Applied Materials\\n4.1\\n(94 Reviews)            7-10 Yrs  \n",
       "4  PHARMACEUTICAL RESEARCH ASSOCIATES INDIA Pvt L...             2-4 Yrs  \n",
       "5  Tata Consultancy Services Ltd.\\n4.0\\n(21095 Re...             4-9 Yrs  \n",
       "6  Shell India Markets Private Limited\\n4.1\\n(623...             6-9 Yrs  \n",
       "7       Myntra Designs Pvt. Ltd.\\n4.2\\n(742 Reviews)             3-6 Yrs  \n",
       "8       Myntra Designs Pvt. Ltd.\\n4.2\\n(742 Reviews)             3-6 Yrs  \n",
       "9       Myntra Designs Pvt. Ltd.\\n4.2\\n(742 Reviews)             4-9 Yrs  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importing chromedriver\n",
    "driver=webdriver.Chrome(\"chromedriver.exe\")\n",
    "\n",
    "#getting Url\n",
    "url=\"https://www.naukri.com/\"\n",
    "driver.get(url)\n",
    "search_bar=driver.find_element_by_id(\"qsb-keyword-sugg\")   #search bar\n",
    "search_bar.send_keys(\"Data Analyst\")  #writing on search bar\n",
    "search_loc=driver.find_element_by_id(\"qsb-location-sugg\") #finding job location bar\n",
    "search_loc.send_keys(\"Banglore\") # setting banglore location\n",
    "\n",
    "#click on search button:\n",
    "search_btn=driver.find_element_by_xpath(\"//button[@class='btn']\")\n",
    "search_btn.click()\n",
    "\n",
    "time.sleep(4)\n",
    "# Extracting Data\n",
    "title=[]  #empty box\n",
    "loc=[]   #empty box\n",
    "cname=[] #empty box\n",
    "experiance=[] #empty box\n",
    "\n",
    "#titles\n",
    "titles=driver.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in titles:\n",
    "    title.append(i.text)\n",
    "title=title[:10]\n",
    "\n",
    "# extracting location\n",
    "l=driver.find_elements_by_xpath('//li[@class=\"fleft grey-text br2 placeHolderLi location\"]/span')\n",
    "for i in l:\n",
    "    loc.append(i.text)\n",
    "loc=loc[:10]\n",
    "\n",
    "#extracting companies names\n",
    "com=driver.find_elements_by_xpath('//div[@class=\"mt-7 companyInfo subheading lh16\"]')\n",
    "for i in com:\n",
    "    cname.append(i.text)\n",
    "cname=cname[:10]\n",
    "\n",
    "# extracting experiance data\n",
    "e=driver.find_elements_by_xpath('//li[@class=\"fleft grey-text br2 placeHolderLi experience\"]')\n",
    "for i in e:\n",
    "    experiance.append(i.text)\n",
    "experiance=experiance[:10]\n",
    "\n",
    "driver.close()\n",
    "#Making DataFrame\n",
    "ans1=pd.DataFrame({})\n",
    "ans1[\"Job_Title\"]=title\n",
    "ans1[\"Location\"]=loc\n",
    "ans1[\"Company_Name\"]=cname\n",
    "ans1[\"Experiance_Required\"]=experiance\n",
    "ans1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2\n",
    "Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name, full job-description. You have to scrape first 10 jobs data.\n",
    "This task will be done in following steps:\n",
    "1. first get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill,Designations,Companies” field and enter “Bangalore” in “enter the location” field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you ge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Job_Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist / Data Analyst -Business Analyst</td>\n",
       "      <td>Mumbai, Hyderabad/Secunderabad, Pune, Gurgaon/...</td>\n",
       "      <td>Inflexion Analytix Private Limited</td>\n",
       "      <td>Job Role : Data Scientist/Data Analyst /Busine...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Senior Data Scientist, Modeling</td>\n",
       "      <td>Kolkata, Gurgaon/Gurugram, Bangalore/Bengaluru...</td>\n",
       "      <td>Nielsen</td>\n",
       "      <td>We wont say we can predict the future, but our...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Senior Data Scientist - Credit risk</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Scienaptic Systems</td>\n",
       "      <td>Responsibilities and duties Focus on developin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Intel Technology India Pvt Ltd</td>\n",
       "      <td>We are seeking an outstanding Lead Data Scient...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Hiring For DATA Scientist - ON Contract Basis ...</td>\n",
       "      <td>Hyderabad/Secunderabad, Bangalore/Bengaluru, M...</td>\n",
       "      <td>GlobalEdx Learning and Technology Solution Pvt...</td>\n",
       "      <td>Dear Aspirant,\\n\\nGreetings from Globaledx\\n\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Senior Data Scientist - Chatbot &amp; NLP</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Gojek Tech</td>\n",
       "      <td>What You Will Do\\nWork with Data Scientists, M...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job_Title  \\\n",
       "0    Data Scientist / Data Analyst -Business Analyst   \n",
       "1                    Senior Data Scientist, Modeling   \n",
       "2                                                 --   \n",
       "3                                                 --   \n",
       "4                Senior Data Scientist - Credit risk   \n",
       "5                                                 --   \n",
       "6                                                 --   \n",
       "7                                Lead Data Scientist   \n",
       "8  Hiring For DATA Scientist - ON Contract Basis ...   \n",
       "9              Senior Data Scientist - Chatbot & NLP   \n",
       "\n",
       "                                            Location  \\\n",
       "0  Mumbai, Hyderabad/Secunderabad, Pune, Gurgaon/...   \n",
       "1  Kolkata, Gurgaon/Gurugram, Bangalore/Bengaluru...   \n",
       "2                                                 --   \n",
       "3                                                 --   \n",
       "4                                Bangalore/Bengaluru   \n",
       "5                                                 --   \n",
       "6                                                 --   \n",
       "7                                Bangalore/Bengaluru   \n",
       "8  Hyderabad/Secunderabad, Bangalore/Bengaluru, M...   \n",
       "9                                Bangalore/Bengaluru   \n",
       "\n",
       "                                        Company_Name  \\\n",
       "0                 Inflexion Analytix Private Limited   \n",
       "1                                            Nielsen   \n",
       "2                                                 --   \n",
       "3                                                 --   \n",
       "4                                 Scienaptic Systems   \n",
       "5                                                 --   \n",
       "6                                                 --   \n",
       "7                     Intel Technology India Pvt Ltd   \n",
       "8  GlobalEdx Learning and Technology Solution Pvt...   \n",
       "9                                         Gojek Tech   \n",
       "\n",
       "                                     Job_Description  \n",
       "0  Job Role : Data Scientist/Data Analyst /Busine...  \n",
       "1  We wont say we can predict the future, but our...  \n",
       "2                                                 --  \n",
       "3                                                 --  \n",
       "4  Responsibilities and duties Focus on developin...  \n",
       "5                                                 --  \n",
       "6                                                 --  \n",
       "7  We are seeking an outstanding Lead Data Scient...  \n",
       "8  Dear Aspirant,\\n\\nGreetings from Globaledx\\n\\n...  \n",
       "9  What You Will Do\\nWork with Data Scientists, M...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importing chrome drive\n",
    "driver=webdriver.Chrome(\"chromedriver.exe\")\n",
    "#loading url\n",
    "driver.get(\"https://www.naukri.com/\")\n",
    "time.sleep(3)\n",
    "\n",
    "#loacating search bar\n",
    "search_bar=driver.find_element_by_id(\"qsb-keyword-sugg\")\n",
    "\n",
    "\n",
    "#writing on search bar\n",
    "search_bar.send_keys(\"Data Scientist\")\n",
    "\n",
    "#finding job location bar\n",
    "search_loc=driver.find_element_by_id(\"qsb-location-sugg\")\n",
    "\n",
    "\n",
    "# setting banglore location\n",
    "search_loc.send_keys(\"Banglore\")\n",
    "\n",
    "#click on search button:\n",
    "search_btn=driver.find_element_by_xpath(\"//button[@class='btn']\")\n",
    "search_btn.click()\n",
    "time.sleep(3)\n",
    "\n",
    "#getting url\n",
    "url=driver.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]')\n",
    "\n",
    "urls=[]\n",
    "for i in url:\n",
    "    urls.append(i.get_attribute(\"href\"))\n",
    "\n",
    "#emptybox\n",
    "titles=[]\n",
    "loc=[]\n",
    "cname=[]\n",
    "des=[]\n",
    "\n",
    "#extracting data\n",
    "for i in urls[:10]:\n",
    "    driver.get(i)\n",
    "    time.sleep(3)\n",
    "  \n",
    "    #extractig jobtitles \n",
    "    try:\n",
    "        job=driver.find_element_by_xpath('//h1[@class=\"jd-header-title\"]')\n",
    "        titles.append(job.text)\n",
    "    except NoSuchElementException:\n",
    "        titles.append(\"--\")\n",
    "\n",
    "    #extractig locations\n",
    "    try:\n",
    "        k=driver.find_element_by_xpath('//div[@class=\"loc\"]')\n",
    "        loc.append(k.text)\n",
    "    except NoSuchElementException:\n",
    "        loc.append(\"--\")\n",
    "   \n",
    "   #extractig cname  \n",
    "    try:\n",
    "        l=driver.find_element_by_xpath(\"//a[@class='pad-rt-8']\")\n",
    "        cname.append(l.text)\n",
    "    except NoSuchElementException:\n",
    "        cname.append(\"--\")\n",
    "\n",
    "    #extracting Description\n",
    "    try:\n",
    "        z=driver.find_element_by_xpath('//div[@class=\"dang-inner-html\"]')\n",
    "        des.append(z.text)\n",
    "    except NoSuchElementException:\n",
    "        des.append(\"--\")\n",
    "\n",
    "driver.close()\n",
    "#Making DataFrame\n",
    "ans2=pd.DataFrame({})\n",
    "ans2[\"Job_Title\"]=titles\n",
    "ans2[\"Location\"]=loc\n",
    "ans2[\"Company_Name\"]=cname\n",
    "ans2[\"Job_Description\"]=des\n",
    "ans2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3\n",
    "In this question you have to scrape data using the filters available on the webpage\n",
    "You have to use the location and salary filter.\n",
    "You have to scrape data for “Data Scientist” designation for first 10 job results.\n",
    "You have to scrape the job-title, job-location, company_name, experience_required.\n",
    "The location filter to be used is “Delhi/NCR”\n",
    "The salary filter to be used is “3-6” lakhs\n",
    "The task will be done as shown in the below steps:\n",
    "1. first get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill,Designations,Companies” field .\n",
    "Then click the search button.\n",
    "4. Then apply the location filter and salary filter by checking the respective boxes\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Experiance_required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist / Data Analyst -Business Analyst</td>\n",
       "      <td>Mumbai, Hyderabad/Secunderabad, Pune, Gurgaon/...</td>\n",
       "      <td>Inflexion Analytix Private Limited</td>\n",
       "      <td>0-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist - High growth VC backed Influen...</td>\n",
       "      <td>Bangalore/Bengaluru, Delhi / NCR, Mumbai (All ...</td>\n",
       "      <td>Ravgins International Pvt. Ltd.</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Excellent opportunity For Data Scientist</td>\n",
       "      <td>Noida, Bangalore/Bengaluru</td>\n",
       "      <td>NEC CORPORATION INDIA PRIVATE LIMITED</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>New Delhi, Gurgaon/Gurugram, Delhi / NCR</td>\n",
       "      <td>Mobikwik</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DATA Scientist – Gurgaon (Exp 3-6 years)</td>\n",
       "      <td>Gurgaon/Gurugram, Delhi / NCR</td>\n",
       "      <td>CRESCENDO GLOBAL LEADERSHIP HIRING INDIA PRIVA...</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DATA Scientist – Gurgaon (Exp 3-6 years)</td>\n",
       "      <td>Gurgaon/Gurugram, Delhi / NCR</td>\n",
       "      <td>CRESCENDO GLOBAL LEADERSHIP HIRING INDIA PRIVA...</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist - Noida</td>\n",
       "      <td>Noida</td>\n",
       "      <td>Optum Global Solutions (India) Private Limited</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist - Noida/ B'lore</td>\n",
       "      <td>Noida, Bangalore/Bengaluru</td>\n",
       "      <td>NEC CORPORATION INDIA PRIVATE LIMITED</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Noida, Hyderabad/Secunderabad, Bangalore/Benga...</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, Delhi / NCR, Mumbai (All ...</td>\n",
       "      <td>Cloudstrats Technologies Private Limited</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job_Title  \\\n",
       "0    Data Scientist / Data Analyst -Business Analyst   \n",
       "1  Data Scientist - High growth VC backed Influen...   \n",
       "2           Excellent opportunity For Data Scientist   \n",
       "3                                     Data Scientist   \n",
       "4           DATA Scientist – Gurgaon (Exp 3-6 years)   \n",
       "5           DATA Scientist – Gurgaon (Exp 3-6 years)   \n",
       "6                             Data Scientist - Noida   \n",
       "7                     Data Scientist - Noida/ B'lore   \n",
       "8                                     Data Scientist   \n",
       "9                                     Data Scientist   \n",
       "\n",
       "                                            Location  \\\n",
       "0  Mumbai, Hyderabad/Secunderabad, Pune, Gurgaon/...   \n",
       "1  Bangalore/Bengaluru, Delhi / NCR, Mumbai (All ...   \n",
       "2                         Noida, Bangalore/Bengaluru   \n",
       "3           New Delhi, Gurgaon/Gurugram, Delhi / NCR   \n",
       "4                      Gurgaon/Gurugram, Delhi / NCR   \n",
       "5                      Gurgaon/Gurugram, Delhi / NCR   \n",
       "6                                              Noida   \n",
       "7                         Noida, Bangalore/Bengaluru   \n",
       "8  Noida, Hyderabad/Secunderabad, Bangalore/Benga...   \n",
       "9  Bangalore/Bengaluru, Delhi / NCR, Mumbai (All ...   \n",
       "\n",
       "                                        Company_Name Experiance_required  \n",
       "0                 Inflexion Analytix Private Limited             0-3 Yrs  \n",
       "1                    Ravgins International Pvt. Ltd.             3-5 Yrs  \n",
       "2              NEC CORPORATION INDIA PRIVATE LIMITED             3-7 Yrs  \n",
       "3                                           Mobikwik             3-5 Yrs  \n",
       "4  CRESCENDO GLOBAL LEADERSHIP HIRING INDIA PRIVA...             3-6 Yrs  \n",
       "5  CRESCENDO GLOBAL LEADERSHIP HIRING INDIA PRIVA...             3-6 Yrs  \n",
       "6     Optum Global Solutions (India) Private Limited             3-5 Yrs  \n",
       "7              NEC CORPORATION INDIA PRIVATE LIMITED             3-8 Yrs  \n",
       "8                             IBM India Pvt. Limited             4-9 Yrs  \n",
       "9           Cloudstrats Technologies Private Limited             5-8 Yrs  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loading webdriver\n",
    "driver=webdriver.Chrome(\"chromedriver.exe\")\n",
    "#calling site\n",
    "driver.get(\"https://www.naukri.com/\")\n",
    "#extraction preocess\n",
    "search_bar=driver.find_element_by_id(\"qsb-keyword-sugg\") #search bar\n",
    "search_bar.clear()  #clearing search bar\n",
    "search_bar.send_keys(\"Data Scientist\")   #inserting \"Data science\" in search bar\n",
    "search_btn=driver.find_element_by_xpath(\"//button[@class='btn']\")\n",
    "search_btn.click() #clicking on search button\n",
    "time.sleep(4)\n",
    "driver.find_element_by_xpath('//*[@title=\"Delhi / NCR\"]').click()   #setting location filter delhi\n",
    "time.sleep(4)\n",
    "driver.find_element_by_xpath('//*[@title=\"3-6 Lakhs\"]').click()   #setting salary\n",
    "time.sleep(4)\n",
    "#extracting the required data\n",
    "titles=[] #empty list for job_title\n",
    "loc=[] #empty list for location\n",
    "cname=[] #empty list for company name\n",
    "expr=[] #empty list for experiance_requires\n",
    "\n",
    "\n",
    "#job_title\n",
    "title=driver.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in title:\n",
    "    titles.append(i.text)\n",
    "titles=titles[:10]\n",
    "\n",
    "#location\n",
    "location=driver.find_elements_by_xpath('//li[@class=\"fleft grey-text br2 placeHolderLi location\"]')\n",
    "for i in location:\n",
    "    loc.append(i.text)\n",
    "loc=loc[:10]\n",
    "\n",
    "#company_name\n",
    "cn=driver.find_elements_by_xpath('//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in cn:\n",
    "    cname.append(i.text)\n",
    "cname=cname[:10]\n",
    "\n",
    "#experiance_required\n",
    "exr=driver.find_elements_by_xpath('//li[@class=\"fleft grey-text br2 placeHolderLi experience\"]')\n",
    "for i in exr:\n",
    "    expr.append(i.text)\n",
    "expr=expr[:10]\n",
    "\n",
    "driver.close()\n",
    "#Making DataFrame\n",
    "ans3=pd.DataFrame({})\n",
    "ans3[\"Job_Title\"]=titles\n",
    "ans3[\"Location\"]=loc\n",
    "ans3[\"Company_Name\"]=cname\n",
    "ans3[\"Experiance_required\"]=expr\n",
    "ans3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 \n",
    "Write a python program to scrape data for first 10 job results for Data scientist Designation in Noida location. You have to scrape company_name, No. of days ago when job was posted, Rating of the company.\n",
    "This task will be done in following steps:\n",
    "1. first get the webpage https://www.glassdoor.co.in/index.htm\n",
    "2. Enter “Data Scientist” in “Job Title,Keyword,Company” field and enter “Noida” in “location” field.\n",
    "3. Then click the search button. \n",
    "4. Then scrape the data for the first 10 jobs results you get in the above shown page.\n",
    "Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company_name</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Posted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ericsson</td>\n",
       "      <td>4.1</td>\n",
       "      <td>12d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CRMNEXT</td>\n",
       "      <td>3.6</td>\n",
       "      <td>10d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Biz2Credit Inc</td>\n",
       "      <td>3.8</td>\n",
       "      <td>30d+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Techlive</td>\n",
       "      <td>5.0</td>\n",
       "      <td>30d+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Salasar New Age Technologies</td>\n",
       "      <td>3.6</td>\n",
       "      <td>30d+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Apsidata Solutions</td>\n",
       "      <td>3.8</td>\n",
       "      <td>2d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CRMNEXT</td>\n",
       "      <td>4.1</td>\n",
       "      <td>10d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Trained Education</td>\n",
       "      <td>4.4</td>\n",
       "      <td>24h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Salasar New Age Technologies</td>\n",
       "      <td>3.8</td>\n",
       "      <td>30d+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>WishFin</td>\n",
       "      <td>3.6</td>\n",
       "      <td>30d+</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   company_name Rating Posted\n",
       "0                      Ericsson    4.1    12d\n",
       "1                       CRMNEXT    3.6    10d\n",
       "2                Biz2Credit Inc    3.8   30d+\n",
       "3                      Techlive    5.0   30d+\n",
       "4  Salasar New Age Technologies    3.6   30d+\n",
       "5            Apsidata Solutions    3.8     2d\n",
       "6                       CRMNEXT    4.1    10d\n",
       "7        Data Trained Education    4.4    24h\n",
       "8  Salasar New Age Technologies    3.8   30d+\n",
       "9                       WishFin    3.6   30d+"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importing chromedriver\n",
    "driver=webdriver.Chrome(\"chromedriver.exe\")\n",
    "\n",
    "#getting Url\n",
    "url=\"https://www.glassdoor.co.in/Job/index.htm\"\n",
    "driver.get(url)\n",
    "search_bar=driver.find_element_by_id(\"KeywordSearch\")   #search bar\n",
    "search_bar.send_keys(\"Data Scientist\")  #writing on search bar\n",
    "search_loc=driver.find_element_by_id(\"LocationSearch\") #finding job location bar\n",
    "search_loc.send_keys(\"Noida\") # setting Noida location\n",
    "\n",
    "#click on search button:\n",
    "search_btn=driver.find_element_by_xpath(\"//button[@class='gd-btn-mkt']\")\n",
    "search_btn.click()\n",
    "\n",
    "time.sleep(4)\n",
    "# Extracting Data\n",
    "cname=[]  #empty box\n",
    "postd=[]   #empty box\n",
    "rating=[] #empty box\n",
    "\n",
    "#Company name\n",
    "titles=driver.find_elements_by_xpath('//div[@class=\"d-flex justify-content-between align-items-start\"]/a')\n",
    "for i in titles:\n",
    "    cname.append(i.text)\n",
    "cname=cname[:10]\n",
    "\n",
    "# extracting rating\n",
    "r=driver.find_elements_by_xpath('//span[@class=\"css-19pjha7 e1cjmv6j1\"]')\n",
    "for i in r:\n",
    "    rating.append(i.text)\n",
    "rating=rating[:10]\n",
    "\n",
    "#extracting no.of day before posted\n",
    "com=driver.find_elements_by_xpath('//div[@class=\"d-flex align-items-end pl-std css-mi55ob\"]')\n",
    "for i in com:\n",
    "    postd.append(i.text)\n",
    "postd=postd[:10]\n",
    "\n",
    "driver.close()\n",
    "#Making DataFrame\n",
    "ans4=pd.DataFrame({})\n",
    "ans4[\"company_name\"]=cname\n",
    "ans4[\"Rating\"]=rating\n",
    "ans4[\"Posted\"]=postd\n",
    "ans4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 \n",
    "Write a python program to scrape the salary data for Data Scientist designation in Noida location.\n",
    "You have to scrape Company name, Number of salaries, Average salary, Min salary, Max Salary.\n",
    "The above task will be, done as shown in the below steps:\n",
    "1. first get the webpage https://www.glassdoor.co.in/Salaries/index.htm\n",
    "2. Enter “Data Scientist” in Job title field and “Noida” in location field.\n",
    "3. Click the search button.\n",
    "4.Scrape data for first 10 companies. Scrape the min salary, max salary, company name, Average salary and rating of the company.\n",
    "5..Store the data in a dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>No. of salaries</th>\n",
       "      <th>Avg salaries</th>\n",
       "      <th>Minimum salaries</th>\n",
       "      <th>Maxmium salaries</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tata Consultancy Services</td>\n",
       "      <td>16 salaries</td>\n",
       "      <td>₹ 6,11,228/yr</td>\n",
       "      <td>₹343K</td>\n",
       "      <td>₹1,095K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Accenture</td>\n",
       "      <td>14 salaries</td>\n",
       "      <td>₹ 11,46,533/yr</td>\n",
       "      <td>₹577K</td>\n",
       "      <td>₹2,213K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IBM</td>\n",
       "      <td>14 salaries</td>\n",
       "      <td>₹ 8,97,795/yr</td>\n",
       "      <td>₹586K</td>\n",
       "      <td>₹2,730K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ericsson-Worldwide</td>\n",
       "      <td>14 salaries</td>\n",
       "      <td>₹ 7,38,057/yr</td>\n",
       "      <td>₹355K</td>\n",
       "      <td>₹1,613K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Delhivery</td>\n",
       "      <td>14 salaries</td>\n",
       "      <td>₹ 12,39,781/yr</td>\n",
       "      <td>₹450K</td>\n",
       "      <td>₹11,622K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>UnitedHealth Group</td>\n",
       "      <td>11 salaries</td>\n",
       "      <td>₹ 13,36,142/yr</td>\n",
       "      <td>₹1,069K</td>\n",
       "      <td>₹1,520K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Valiance Solutions</td>\n",
       "      <td>9 salaries</td>\n",
       "      <td>₹ 8,15,192/yr</td>\n",
       "      <td>₹502K</td>\n",
       "      <td>₹1,465K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ZS Associates</td>\n",
       "      <td>8 salaries</td>\n",
       "      <td>₹ 11,35,221/yr</td>\n",
       "      <td>₹202K</td>\n",
       "      <td>₹1,809K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>EXL Service</td>\n",
       "      <td>8 salaries</td>\n",
       "      <td>₹ 11,44,243/yr</td>\n",
       "      <td>₹575K</td>\n",
       "      <td>₹1,520K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Optum Global Solutions</td>\n",
       "      <td>8 salaries</td>\n",
       "      <td>₹ 14,13,288/yr</td>\n",
       "      <td>₹1,014K</td>\n",
       "      <td>₹2,149K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Company No. of salaries    Avg salaries Minimum salaries  \\\n",
       "0  Tata Consultancy Services     16 salaries   ₹ 6,11,228/yr            ₹343K   \n",
       "1                  Accenture     14 salaries  ₹ 11,46,533/yr            ₹577K   \n",
       "2                        IBM     14 salaries   ₹ 8,97,795/yr            ₹586K   \n",
       "3         Ericsson-Worldwide     14 salaries   ₹ 7,38,057/yr            ₹355K   \n",
       "4                  Delhivery     14 salaries  ₹ 12,39,781/yr            ₹450K   \n",
       "5         UnitedHealth Group     11 salaries  ₹ 13,36,142/yr          ₹1,069K   \n",
       "6         Valiance Solutions      9 salaries   ₹ 8,15,192/yr            ₹502K   \n",
       "7              ZS Associates      8 salaries  ₹ 11,35,221/yr            ₹202K   \n",
       "8                EXL Service      8 salaries  ₹ 11,44,243/yr            ₹575K   \n",
       "9     Optum Global Solutions      8 salaries  ₹ 14,13,288/yr          ₹1,014K   \n",
       "\n",
       "  Maxmium salaries  \n",
       "0          ₹1,095K  \n",
       "1          ₹2,213K  \n",
       "2          ₹2,730K  \n",
       "3          ₹1,613K  \n",
       "4         ₹11,622K  \n",
       "5          ₹1,520K  \n",
       "6          ₹1,465K  \n",
       "7          ₹1,809K  \n",
       "8          ₹1,520K  \n",
       "9          ₹2,149K  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importing chromedriver\n",
    "driver=webdriver.Chrome(\"chromedriver.exe\")\n",
    "\n",
    "#getting Url\n",
    "url=\"https://www.glassdoor.co.in/Salaries/index.htm\"\n",
    "driver.get(url)\n",
    "search_bar=driver.find_element_by_id(\"KeywordSearch\")   #search bar\n",
    "search_bar.send_keys(\"Data Scientist\")  #writing on search bar\n",
    "search_loc=driver.find_element_by_id(\"LocationSearch\") #finding job location bar\n",
    "search_loc.send_keys(\"Noida\") # setting Noida location\n",
    "\n",
    "#click on search button:\n",
    "search_btn=driver.find_element_by_xpath(\"//button[@class='gd-btn-mkt']\")\n",
    "search_btn.click()\n",
    "\n",
    "time.sleep(6)\n",
    "# Extracting Data\n",
    "cname=[]  #empty box\n",
    "nsalaries=[]   #empty box\n",
    "avgsalaries=[] #empty box\n",
    "minmaxsalary=[] #empty box\n",
    "\n",
    "#Company name\n",
    "titles=driver.find_elements_by_xpath('//p[@class=\"m-0 \"]')\n",
    "for i in titles:\n",
    "    cname.append(i.text)\n",
    "cname=cname[:10]\n",
    "\n",
    "# extracting number of salaries\n",
    "n=driver.find_elements_by_xpath('//p[@class=\"css-1uyte9r css-1kuy7z7 m-0 \"]')\n",
    "for i in n:\n",
    "    nsalaries.append(i.text)\n",
    "nsalaries=nsalaries[:10]\n",
    "\n",
    "#extracting average salaries\n",
    "a=driver.find_elements_by_xpath('//div[@class=\"col-2 d-none d-md-flex flex-row justify-content-end\"]')\n",
    "for i in a:\n",
    "    avgsalaries.append(i.text.replace(\"\\n\",\"\"))\n",
    "avgsalaries=avgsalaries[:10]\n",
    "\n",
    "# extracting minimum salaries\n",
    "mi=driver.find_elements_by_xpath('//div[@class=\"common__RangeBarStyle__values d-flex justify-content-between \"]')\n",
    "for i in mi:\n",
    "    minmaxsalary.append(i.text)\n",
    "minmaxsalary=minmaxsalary[:10]\n",
    "#seprating minimum and maximum salary\n",
    "l =minmaxsalary\n",
    "split_list =[i.split() for i in l]\n",
    "flat_list = [item for sublist in split_list for item in sublist]\n",
    "minsalary=flat_list[::2]\n",
    "maxsalary=flat_list[1::2]\n",
    "\n",
    "driver.close()\n",
    "#Making DataFrame\n",
    "ans5=pd.DataFrame({})\n",
    "ans5[\"Company\"]=cname\n",
    "ans5[\"No. of salaries\"]=nsalaries\n",
    "ans5[\"Avg salaries\"]=avgsalaries\n",
    "ans5[\"Minimum salaries\"]=minsalary\n",
    "ans5[\"Maxmium salaries\"]=maxsalary\n",
    "ans5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6\n",
    "Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "4. Discount %\n",
    "To scrape the data you have to go through following steps:\n",
    "1. Go to flipkart webpage by url https://www.flipkart.com/\n",
    "2. Enter “sunglasses” in the search field where “search for products, brands and more” is written and click the search icon\n",
    "3. after that you will reach to a webpage having a lot of sunglasses. From this page you can scrap the required data as usual.\n",
    "4. after scraping data from the first page, go to the “Next” Button at the bottom of the page , then click on it\n",
    "5.Now scrape data from this page as usual\n",
    "6. repeat this until you get data for 100 sunglasses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product_description</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AISLIN</td>\n",
       "      <td>UV Protection, Gradient Round, Shield Sunglass...</td>\n",
       "      <td>₹395</td>\n",
       "      <td>77% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NuVew</td>\n",
       "      <td>UV Protection Retro Square, Wayfarer Sunglasse...</td>\n",
       "      <td>₹314</td>\n",
       "      <td>70% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (Free Size)</td>\n",
       "      <td>₹630</td>\n",
       "      <td>21% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>Gradient, UV Protection Wayfarer Sunglasses (F...</td>\n",
       "      <td>₹621</td>\n",
       "      <td>22% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>UV Protection Retro Square Sunglasses (Free Size)</td>\n",
       "      <td>₹499</td>\n",
       "      <td>77% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Singco India</td>\n",
       "      <td>UV Protection Aviator Sunglasses (57)</td>\n",
       "      <td>₹339</td>\n",
       "      <td>71% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>DEIXELS</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "      <td>₹189</td>\n",
       "      <td>76% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>GANSTA</td>\n",
       "      <td>UV Protection Cat-eye Sunglasses (60)</td>\n",
       "      <td>₹281</td>\n",
       "      <td>85% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>Others Retro Square Sunglasses (Free Size)</td>\n",
       "      <td>₹838</td>\n",
       "      <td>6% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>NuVew</td>\n",
       "      <td>UV Protection, Mirrored Retro Square Sunglasse...</td>\n",
       "      <td>₹419</td>\n",
       "      <td>71% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Brand                                Product_description Price  \\\n",
       "0           AISLIN  UV Protection, Gradient Round, Shield Sunglass...  ₹395   \n",
       "1            NuVew  UV Protection Retro Square, Wayfarer Sunglasse...  ₹314   \n",
       "2         Fastrack   UV Protection Rectangular Sunglasses (Free Size)  ₹630   \n",
       "3         Fastrack  Gradient, UV Protection Wayfarer Sunglasses (F...  ₹621   \n",
       "4   ROZZETTA CRAFT  UV Protection Retro Square Sunglasses (Free Size)  ₹499   \n",
       "..             ...                                                ...   ...   \n",
       "95    Singco India              UV Protection Aviator Sunglasses (57)  ₹339   \n",
       "96         DEIXELS      UV Protection Wayfarer Sunglasses (Free Size)  ₹189   \n",
       "97          GANSTA              UV Protection Cat-eye Sunglasses (60)  ₹281   \n",
       "98        Fastrack         Others Retro Square Sunglasses (Free Size)  ₹838   \n",
       "99           NuVew  UV Protection, Mirrored Retro Square Sunglasse...  ₹419   \n",
       "\n",
       "   Discount  \n",
       "0   77% off  \n",
       "1   70% off  \n",
       "2   21% off  \n",
       "3   22% off  \n",
       "4   77% off  \n",
       "..      ...  \n",
       "95  71% off  \n",
       "96  76% off  \n",
       "97  85% off  \n",
       "98   6% off  \n",
       "99  71% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importing chromedriver\n",
    "driver=webdriver.Chrome(\"chromedriver.exe\")\n",
    "\n",
    "#getting Url\n",
    "url=\"https://www.flipkart.com/\"\n",
    "driver.get(url)\n",
    "driver.find_element_by_xpath('//button[@class=\"_2KpZ6l _2doB4z\"]').click()\n",
    "time.sleep(2)\n",
    "search_bar=driver.find_element_by_xpath('//*[@title=\"Search for products, brands and more\"]')   #search bar\n",
    "search_bar.click()\n",
    "search_bar.send_keys(\"sunglasses\")  #writing on search bar\n",
    "\n",
    "#click on search button:\n",
    "search_btn=driver.find_element_by_xpath(\"//button[@class='L0Z3Pu']\")\n",
    "search_btn.click()\n",
    "\n",
    "time.sleep(4)\n",
    "# Extracting Data\n",
    "brand=[]  #empty box\n",
    "pdes=[]   #empty box\n",
    "price=[] #empty box\n",
    "discount=[] #empty box\n",
    "\n",
    "for i in range(0,3):   #chossing top 3 pages\n",
    "    for j in driver.find_elements_by_xpath('//div[@class=\"_2WkVRV\"]'):   #brand\n",
    "        brand.append(j.text)\n",
    "    for l in driver.find_elements_by_xpath('//a[@class=\"IRpwTa\"]'):      #description\n",
    "        pdes.append(l.text)\n",
    "\n",
    "    for c in driver.find_elements_by_xpath('//div[@class=\"_30jeq3\"]'):   #price\n",
    "        price.append(c.text)\n",
    "\n",
    "    for e in driver.find_elements_by_xpath('//div[@class=\"_3Ay6Sb\"]'):   #discount\n",
    "        discount.append(e.text)\n",
    "    driver.find_element_by_xpath('//a[@class=\"_1LKTO3\"]').click()      #next page\n",
    "    time.sleep(5)\n",
    "\n",
    "#selecting top 100 \n",
    "brand=brand[:100]\n",
    "pdes=pdes[:100]\n",
    "price=price[:100]\n",
    "discount=discount[:100]\n",
    "\n",
    "driver.close()\n",
    "#Making DataFrame\n",
    "ans6=pd.DataFrame({})\n",
    "ans6[\"Brand\"]=brand\n",
    "ans6[\"Product_description\"]=pdes\n",
    "ans6[\"Price\"]=price\n",
    "ans6[\"Discount\"]=discount\n",
    "ans6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7\n",
    "Scrape 100 reviews data from flipkart.com for iphone11 phone. \n",
    "You have to go the link: https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace.\n",
    "As shown in the above page you have to scrape the tick marked attributes.\n",
    "These are\n",
    "1. Rating\n",
    "2. Review_summary\n",
    "3. Full review\n",
    "You have to scrape this data for first 100 reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review_summaru</th>\n",
       "      <th>Detail_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Brilliant</td>\n",
       "      <td>The Best Phone for the Money\\n\\nThe iPhone 11 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Amazing phone with great cameras and better ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Great product</td>\n",
       "      <td>Amazing Powerful and Durable Gadget.\\n\\nI’m am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>Previously I was using one plus 3t it was a gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Good choice</td>\n",
       "      <td>So far it’s been an AMAZING experience coming ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>iphone 11 is a very good phone to buy only if ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>It’s a must buy who is looking for an upgrade ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5</td>\n",
       "      <td>Fabulous!</td>\n",
       "      <td>This is my first iOS phone. I am very happy wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Value for money❤️❤️\\nIts awesome mobile phone ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5</td>\n",
       "      <td>Wonderful</td>\n",
       "      <td>*Review after 10 months of usage*\\nDoesn't see...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating      Review_summaru  \\\n",
       "0       5           Brilliant   \n",
       "1       5    Perfect product!   \n",
       "2       5       Great product   \n",
       "3       5   Worth every penny   \n",
       "4       4         Good choice   \n",
       "..    ...                 ...   \n",
       "95      5  Highly recommended   \n",
       "96      5    Perfect product!   \n",
       "97      5           Fabulous!   \n",
       "98      5    Perfect product!   \n",
       "99      5           Wonderful   \n",
       "\n",
       "                                       Detail_summary  \n",
       "0   The Best Phone for the Money\\n\\nThe iPhone 11 ...  \n",
       "1   Amazing phone with great cameras and better ba...  \n",
       "2   Amazing Powerful and Durable Gadget.\\n\\nI’m am...  \n",
       "3   Previously I was using one plus 3t it was a gr...  \n",
       "4   So far it’s been an AMAZING experience coming ...  \n",
       "..                                                ...  \n",
       "95  iphone 11 is a very good phone to buy only if ...  \n",
       "96  It’s a must buy who is looking for an upgrade ...  \n",
       "97  This is my first iOS phone. I am very happy wi...  \n",
       "98  Value for money❤️❤️\\nIts awesome mobile phone ...  \n",
       "99  *Review after 10 months of usage*\\nDoesn't see...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importing chromedriver\n",
    "driver=webdriver.Chrome(\"chromedriver.exe\")\n",
    "\n",
    "#getting Url\n",
    "url=\"https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace\"\n",
    "driver.get(url)\n",
    "driver.find_element_by_xpath('//div[@class=\"_3UAT2v _16PBlm\"]').click()\n",
    "time.sleep(2)\n",
    "\n",
    "# Extracting Data\n",
    "rating=[]  #empty box\n",
    "rsum=[]   #empty box\n",
    "fsum=[] #empty box\n",
    "\n",
    "\n",
    "for i in range(0,11):   #chossing top 3 pages\n",
    "    for j in driver.find_elements_by_xpath('//div[@class=\"_3LWZlK _1BLPMq\"]'):   #Rating\n",
    "        rating.append(j.text)\n",
    "    for l in driver.find_elements_by_xpath('//p[@class=\"_2-N8zT\"]'):      #Review_summary\n",
    "        rsum.append(l.text)\n",
    "    for c in driver.find_elements_by_xpath('//div[@class=\"t-ZTKy\"]'):   #Detail_summary\n",
    "        fsum.append(c.text)\n",
    "    driver.find_element_by_xpath('//a[@class=\"_1LKTO3\"]').click()      #next page\n",
    "    time.sleep(5)\n",
    "\n",
    "\n",
    "driver.close()\n",
    "#selecting top 100 \n",
    "rating=rating[:100]\n",
    "rsum=rsum[:100]\n",
    "fsum=fsum[:100]\n",
    "\n",
    "#Making DataFrame\n",
    "ans7=pd.DataFrame({})\n",
    "ans7[\"Rating\"]=rating\n",
    "ans7[\"Review_summaru\"]=rsum\n",
    "ans7[\"Detail_summary\"]=fsum\n",
    "ans7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8\n",
    "Scrape data for first 100 sneakers you find when you visit flipkart.com and search for “sneakers” in the search field.\n",
    "You have to scrape 4 attributes of each sneaker :\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "4. discount %\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product_description</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Deals4you</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹449</td>\n",
       "      <td>55% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Skymate</td>\n",
       "      <td>Casual Sneakers Shoes For Men Sneakers For Men</td>\n",
       "      <td>₹224</td>\n",
       "      <td>55% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Robbie jones</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹399</td>\n",
       "      <td>60% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Robbie jones</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹474</td>\n",
       "      <td>52% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aadi</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹298</td>\n",
       "      <td>70% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Stefano Rads</td>\n",
       "      <td>Sneakers Sneakers For Men</td>\n",
       "      <td>₹242</td>\n",
       "      <td>57% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Birde</td>\n",
       "      <td>Exclusive Sneaker For Men</td>\n",
       "      <td>₹842</td>\n",
       "      <td>57% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Robbie jones</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹428</td>\n",
       "      <td>51% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>World Wear Footwear</td>\n",
       "      <td>Latest Stylish Casual sneakers for men | Lace ...</td>\n",
       "      <td>₹240</td>\n",
       "      <td>54% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>ASTEROID</td>\n",
       "      <td>Sneakers for men(black_6) Sneakers For Men</td>\n",
       "      <td>₹451</td>\n",
       "      <td>60% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Brand                                Product_description  \\\n",
       "0             Deals4you                                   Sneakers For Men   \n",
       "1               Skymate     Casual Sneakers Shoes For Men Sneakers For Men   \n",
       "2          Robbie jones                                   Sneakers For Men   \n",
       "3          Robbie jones                                   Sneakers For Men   \n",
       "4                  aadi                                   Sneakers For Men   \n",
       "..                  ...                                                ...   \n",
       "95         Stefano Rads                          Sneakers Sneakers For Men   \n",
       "96                Birde                          Exclusive Sneaker For Men   \n",
       "97         Robbie jones                                   Sneakers For Men   \n",
       "98  World Wear Footwear  Latest Stylish Casual sneakers for men | Lace ...   \n",
       "99             ASTEROID         Sneakers for men(black_6) Sneakers For Men   \n",
       "\n",
       "   Price Discount  \n",
       "0   ₹449  55% off  \n",
       "1   ₹224  55% off  \n",
       "2   ₹399  60% off  \n",
       "3   ₹474  52% off  \n",
       "4   ₹298  70% off  \n",
       "..   ...      ...  \n",
       "95  ₹242  57% off  \n",
       "96  ₹842  57% off  \n",
       "97  ₹428  51% off  \n",
       "98  ₹240  54% off  \n",
       "99  ₹451  60% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importing chromedriver\n",
    "driver=webdriver.Chrome(\"chromedriver.exe\")\n",
    "\n",
    "#getting Url\n",
    "url=\"https://www.flipkart.com/\"\n",
    "driver.get(url)\n",
    "driver.find_element_by_xpath('//button[@class=\"_2KpZ6l _2doB4z\"]').click()\n",
    "time.sleep(2)\n",
    "search_bar=driver.find_element_by_xpath('//*[@title=\"Search for products, brands and more\"]')   #search bar\n",
    "search_bar.click()\n",
    "search_bar.send_keys(\"sneakers\")  #writing on search bar\n",
    "\n",
    "#click on search button:\n",
    "search_btn=driver.find_element_by_xpath(\"//button[@class='L0Z3Pu']\")\n",
    "search_btn.click()\n",
    "\n",
    "time.sleep(4)\n",
    "# Extracting Data\n",
    "brand=[]  #empty box\n",
    "pdes=[]   #empty box\n",
    "price=[] #empty box\n",
    "discount=[] #empty box\n",
    "\n",
    "for i in range(0,4):   #chossing top 4 pages\n",
    "    for j in driver.find_elements_by_xpath('//div[@class=\"_2WkVRV\"]'):   #brand\n",
    "        brand.append(j.text)\n",
    "    for l in driver.find_elements_by_xpath('//a[@class=\"IRpwTa\"]'):      #description\n",
    "        pdes.append(l.text)\n",
    "\n",
    "    for c in driver.find_elements_by_xpath('//div[@class=\"_30jeq3\"]'):   #price\n",
    "        price.append(c.text)\n",
    "\n",
    "    for e in driver.find_elements_by_xpath('//div[@class=\"_3Ay6Sb\"]'):   #discount\n",
    "        discount.append(e.text)\n",
    "    driver.find_element_by_xpath('//a[@class=\"_1LKTO3\"]').click()      #next page\n",
    "    time.sleep(5)\n",
    "\n",
    "#selecting top 100 \n",
    "brand=brand[:100]\n",
    "pdes=pdes[:100]\n",
    "price=price[:100]\n",
    "discount=discount[:100]\n",
    "\n",
    "driver.close()\n",
    "#Making DataFrame\n",
    "ans8=pd.DataFrame({})\n",
    "ans8[\"Brand\"]=brand\n",
    "ans8[\"Product_description\"]=pdes\n",
    "ans8[\"Price\"]=price\n",
    "ans8[\"Discount\"]=discount\n",
    "ans8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9\n",
    "Go to the link - https://www.myntra.com/shoes\n",
    "Set Price filter to “Rs. 6649 to Rs. 13099” , Color filter to “Black”,\n",
    "And then scrape First 100 shoes data you get. The data should include “Brand” of the shoes , Short Shoe description, price of the shoe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product_description</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Skechers</td>\n",
       "      <td>Men VIPER COMPETITOR Training</td>\n",
       "      <td>Rs. 6999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men JOYRIDE Running Shoes</td>\n",
       "      <td>Rs. 10496Rs. 14995(30% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nike</td>\n",
       "      <td>AIR ZOOM PEGASUS Running Shoes</td>\n",
       "      <td>Rs. 11495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PUMA Motorsport</td>\n",
       "      <td>Unisex Mercedes Running Shoes</td>\n",
       "      <td>Rs. 7999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Men Liberate Nitro Running</td>\n",
       "      <td>Rs. 9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Reebok</td>\n",
       "      <td>Unisex Zig Kinetica II Running</td>\n",
       "      <td>Rs. 9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Saint G</td>\n",
       "      <td>Leather Heeled Boots</td>\n",
       "      <td>Rs. 11800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>FILA</td>\n",
       "      <td>Women Solid Sneakers</td>\n",
       "      <td>Rs. 6999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Kenneth Cole</td>\n",
       "      <td>Women Solid Flat Boots</td>\n",
       "      <td>Rs. 9513Rs. 13590(30% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>ADIDAS</td>\n",
       "      <td>Men Supernova Running Shoes</td>\n",
       "      <td>Rs. 7999Rs. 9999(20% OFF)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Brand             Product_description  \\\n",
       "0          Skechers   Men VIPER COMPETITOR Training   \n",
       "1              Nike       Men JOYRIDE Running Shoes   \n",
       "2              Nike  AIR ZOOM PEGASUS Running Shoes   \n",
       "3   PUMA Motorsport   Unisex Mercedes Running Shoes   \n",
       "4              Puma      Men Liberate Nitro Running   \n",
       "..              ...                             ...   \n",
       "95           Reebok  Unisex Zig Kinetica II Running   \n",
       "96          Saint G            Leather Heeled Boots   \n",
       "97             FILA            Women Solid Sneakers   \n",
       "98     Kenneth Cole          Women Solid Flat Boots   \n",
       "99           ADIDAS     Men Supernova Running Shoes   \n",
       "\n",
       "                          Price  \n",
       "0                      Rs. 6999  \n",
       "1   Rs. 10496Rs. 14995(30% OFF)  \n",
       "2                     Rs. 11495  \n",
       "3                      Rs. 7999  \n",
       "4                      Rs. 9999  \n",
       "..                          ...  \n",
       "95                     Rs. 9999  \n",
       "96                    Rs. 11800  \n",
       "97                     Rs. 6999  \n",
       "98   Rs. 9513Rs. 13590(30% OFF)  \n",
       "99    Rs. 7999Rs. 9999(20% OFF)  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importing chromedriver\n",
    "driver=webdriver.Chrome(\"chromedriver.exe\")\n",
    "\n",
    "#getting Url\n",
    "url=\"https://www.myntra.com/shoes\"\n",
    "driver.get(url)\n",
    "time.sleep(4)\n",
    "driver.find_element_by_xpath(\"//label[@class='common-customCheckbox']\").click()        \n",
    "time.sleep(2)\n",
    "driver.find_element_by_xpath(\"/html/body/div[2]/div/div[1]/main/div[3]/div[1]/section/div/div[5]/ul/li[2]/label\").click()\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "time.sleep(4)\n",
    "# Extracting Data\n",
    "brand=[]  #empty box\n",
    "sdes=[]   #empty box\n",
    "price=[] #empty box\n",
    "\n",
    "\n",
    "for i in range(0,3):   #chossing top 4 pages\n",
    "    for j in driver.find_elements_by_xpath('//h3[@class=\"product-brand\"]'):   #brand\n",
    "        brand.append(j.text)\n",
    "    for l in driver.find_elements_by_xpath('//h4[@class=\"product-product\"]'):      #description\n",
    "        sdes.append(l.text)\n",
    "\n",
    "    for c in driver.find_elements_by_xpath('//div[@class=\"product-price\"]'):   #price\n",
    "        price.append(c.text)\n",
    "\n",
    "   \n",
    "    driver.find_element_by_xpath('//li[@class=\"pagination-next\"]').click()      #next page\n",
    "    time.sleep(3)\n",
    "\n",
    "#selecting top 100 \n",
    "brand=brand[:100]\n",
    "sdes=sdes[:100]\n",
    "price=price[:100]\n",
    "\n",
    "driver.close()\n",
    "#Making DataFrame\n",
    "ans9=pd.DataFrame({})\n",
    "ans9[\"Brand\"]=brand\n",
    "ans9[\"Product_description\"]=sdes\n",
    "ans9[\"Price\"]=price\n",
    "\n",
    "ans9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10\n",
    "Go to webpage https://www.amazon.in/\n",
    "Enter “Laptop” in the search field and then click the search icon.\n",
    "Then set CPU Type filter to “Intel Core i7” and “Intel Core i9” \n",
    "After setting the filters scrape first 10 laptops data. You have to scrape 3 attributes for each laptop:\n",
    "1. title\n",
    "2. Ratings\n",
    "3. Price\n",
    "As shown in the below image as the tick marked attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(Renewed) Lenovo T430 14-inch Laptop (Core i7/...</td>\n",
       "      <td>--</td>\n",
       "      <td>₹ 53,499.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lenovo Ideapad 720s Intel Core i7 8th Gen 13.3...</td>\n",
       "      <td>3.1 out of 5</td>\n",
       "      <td>₹ 89,990.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(Renewed) Dell Intel 6th Gen Core i7-6820HQ 15...</td>\n",
       "      <td>5 out of 5</td>\n",
       "      <td>₹ 78,699.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(Renewed) Dell E7250 Latitude 12.5 Inches Lapt...</td>\n",
       "      <td>3.4 out of 5</td>\n",
       "      <td>₹ 54,499.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(Renewed) Dell Intel 6th Gen Core i7-6820HQ 15...</td>\n",
       "      <td>--</td>\n",
       "      <td>₹ 61,799.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(Renewed) Dell Latitude E6420 14 Inch Laptop (...</td>\n",
       "      <td>--</td>\n",
       "      <td>₹ 43,000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(Renewed) Dell Latitude E6540 Laptop (CORE I7 ...</td>\n",
       "      <td>--</td>\n",
       "      <td>₹ 33,390.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(Renewed) Dell Latitude E7470 14-inch Laptop (...</td>\n",
       "      <td>--</td>\n",
       "      <td>₹ 65,299.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(Renewed) Dell Intel 6th Gen Core i7 6600U 12....</td>\n",
       "      <td>--</td>\n",
       "      <td>₹ 51,768.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(Renewed) Lenovo Intel Core i7 5600U 12.5-Inch...</td>\n",
       "      <td>3.2 out of 5</td>\n",
       "      <td>--</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job_Title        Rating  \\\n",
       "0  (Renewed) Lenovo T430 14-inch Laptop (Core i7/...            --   \n",
       "1  Lenovo Ideapad 720s Intel Core i7 8th Gen 13.3...  3.1 out of 5   \n",
       "2  (Renewed) Dell Intel 6th Gen Core i7-6820HQ 15...    5 out of 5   \n",
       "3  (Renewed) Dell E7250 Latitude 12.5 Inches Lapt...  3.4 out of 5   \n",
       "4  (Renewed) Dell Intel 6th Gen Core i7-6820HQ 15...            --   \n",
       "5  (Renewed) Dell Latitude E6420 14 Inch Laptop (...            --   \n",
       "6  (Renewed) Dell Latitude E6540 Laptop (CORE I7 ...            --   \n",
       "7  (Renewed) Dell Latitude E7470 14-inch Laptop (...            --   \n",
       "8  (Renewed) Dell Intel 6th Gen Core i7 6600U 12....            --   \n",
       "9  (Renewed) Lenovo Intel Core i7 5600U 12.5-Inch...  3.2 out of 5   \n",
       "\n",
       "         Price  \n",
       "0  ₹ 53,499.00  \n",
       "1  ₹ 89,990.00  \n",
       "2  ₹ 78,699.00  \n",
       "3  ₹ 54,499.00  \n",
       "4  ₹ 61,799.00  \n",
       "5  ₹ 43,000.00  \n",
       "6  ₹ 33,390.00  \n",
       "7  ₹ 65,299.00  \n",
       "8  ₹ 51,768.00  \n",
       "9           --  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importing chrome drive\n",
    "driver=webdriver.Chrome(\"chromedriver.exe\")\n",
    "#loading url\n",
    "driver.get(\"https://www.amazon.in/\")\n",
    "time.sleep(3)\n",
    "\n",
    "#loacating search bar\n",
    "search_bar=driver.find_element_by_id(\"twotabsearchtextbox\")\n",
    "\n",
    "\n",
    "#writing on search bar\n",
    "search_bar.send_keys(\"Laptops\")\n",
    "\n",
    "#click on search button:\n",
    "search_btn=driver.find_element_by_id(\"nav-search-submit-button\")\n",
    "search_btn.click()\n",
    "time.sleep(3)\n",
    "\n",
    "#i7 filter\n",
    "filter_bi7=driver.find_elements_by_xpath(\"//span[@class='a-size-base a-color-base']\")\n",
    "for i in filter_bi7:\n",
    "    if i.text==\"Intel Core i7\":\n",
    "        i.click()\n",
    "        break\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#getting url\n",
    "url=driver.find_elements_by_xpath('//a[@class=\"a-link-normal a-text-normal\"]')\n",
    "\n",
    "urls=[]\n",
    "for i in url:\n",
    "    urls.append(i.get_attribute(\"href\"))\n",
    "\n",
    "#emptybox\n",
    "titles=[]\n",
    "rating=[]\n",
    "price=[]\n",
    "\n",
    "#extracting data\n",
    "for i in urls[:10]:\n",
    "    driver.get(i)\n",
    "    time.sleep(3)\n",
    "  \n",
    "    #extractig titles \n",
    "    try:\n",
    "        t=driver.find_element_by_xpath('//span[@class=\"a-size-large product-title-word-break\"]')\n",
    "        titles.append(t.text)\n",
    "    except NoSuchElementException:\n",
    "        titles.append(\"--\")\n",
    "\n",
    "    #extractig rating\n",
    "    try:\n",
    "        k=driver.find_element_by_xpath('//span[@class=\"a-size-medium a-color-base\"]')\n",
    "        rating.append(k.text)\n",
    "    except NoSuchElementException:\n",
    "        rating.append(\"--\")\n",
    "   \n",
    "   #extractig price \n",
    "    try:\n",
    "        l=driver.find_element_by_xpath(\"//span[@class='a-size-medium a-color-price priceBlockBuyingPriceString']\")\n",
    "        price.append(l.text)\n",
    "    except NoSuchElementException:\n",
    "        price.append(\"--\")\n",
    "driver.close()\n",
    "  \n",
    "\n",
    "#Making DataFrame\n",
    "ans10=pd.DataFrame({})\n",
    "ans10[\"Job_Title\"]=titles\n",
    "ans10[\"Rating\"]=rating\n",
    "ans10[\"Price\"]=price\n",
    "\n",
    "ans10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
